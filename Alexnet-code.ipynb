{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d3150e-56e4-4701-89d2-b453fe16d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "# import cv2\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image\n",
    "from IPython.display import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models,transforms,datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6cdc34-55f5-490f-b93b-85cabd348eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"./imgs_less/train\"\n",
    "classes = [c for c in os.listdir(path_train) if not c.startswith(\".\")]\n",
    "classes.sort()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa626a13-bbc3-468c-bca5-52e789c80494",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"./imgs_less/train\"\n",
    "classes = [c for c in os.listdir(path_train) if not c.startswith(\".\")]\n",
    "classes.sort()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8aff34-8065-4faf-a9ae-45a6630e0eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/data/rkj/Rkj_code/project1/test-240-path.xlsx', sheet_name=0)\n",
    "image_paths = df.iloc[:, 0]\n",
    "print(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5d839-2a1f-4310-8436-72a908c15fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_paths = image_paths.apply(lambda x: x.replace('imgs', 'imgs_less'))\n",
    "print(updated_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de03b91d-2f57-45f2-8a8f-09c2e97b531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_paths = image_paths.apply(lambda x: x.replace('imgs', 'imgs_less'))\n",
    "print(updated_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48080df0-31f2-4877-90d9-e19e003febea",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"img\" : [], \"class\" : []}\n",
    "for c in classes:\n",
    "    imgs = [img for img in os.listdir(os.path.join(path_train,c)) if not img.startswith(\".\")]\n",
    "    for img in imgs:\n",
    "        d[\"img\"].append(img)\n",
    "        if c == \"c0\":\n",
    "            d[\"class\"].append(\"c0\")\n",
    "        elif c == \"c1\":\n",
    "            d[\"class\"].append(\"c1\")\n",
    "        elif c == \"c2\":    \n",
    "            d[\"class\"].append(\"c2\")\n",
    "        elif c == \"c3\":    \n",
    "            d[\"class\"].append(\"c3\")\n",
    "        elif c == \"c4\":    \n",
    "            d[\"class\"].append(\"c4\")\n",
    "        elif c == \"c5\":    \n",
    "            d[\"class\"].append(\"c5\")\n",
    "        elif c == \"c6\":    \n",
    "            d[\"class\"].append(\"c6\")\n",
    "        else:\n",
    "            \n",
    "            d[\"class\"].append(\"c7\")\n",
    "df = pd.DataFrame(d)\n",
    "ax = sns.countplot(data=df,x=\"class\")\n",
    "ax.set(title=\"Classes distribution\")\n",
    "print(\"Total number of training data :\",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68876d1-485d-4949-8c66-61e5c94f3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                 transforms.RandomRotation(10),\n",
    "                                 transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf1dee9-12c6-4278-b56c-24b1b443ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.ImageFolder(root = path_train, transform = transform)\n",
    "targets = np.array(data.targets)  # get labels\n",
    "print(len(targets))\n",
    "total_len = len(data)\n",
    "training_len = int(1.0*total_len)\n",
    "print(training_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eadc7c7-be19-4763-8ceb-145466151c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(\n",
    "    np.arange(len(targets)),\n",
    "    test_size=0.5,\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "training_data = Subset(data, train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bad859-b766-4a30-9fb5-4485a44f0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_teat = '/data/rkj/Rkj_code/project1/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f6e83-3200-404c-9da4-3f70e638dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = datasets.ImageFolder(root = path_train, transform = transform)\n",
    "# training_data = data\n",
    "testing_data = datasets.ImageFolder(root = path_teat, transform = transform)\n",
    "print(training_data)\n",
    "print(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf7a32-fef8-4757-846a-a66ab824f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = datasets.ImageFolder(root = path_train, transform = transform)\n",
    "# training_data = data\n",
    "testing_data = datasets.ImageFolder(root = path_teat, transform = transform)\n",
    "print(training_data)\n",
    "print(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e625ba12-344f-4169-bb54-90a71f3c6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = datasets.ImageFolder(root = path_train, transform = transform)\n",
    "# training_data = data\n",
    "testing_data = datasets.ImageFolder(root = path_teat, transform = transform)\n",
    "print(training_data)\n",
    "print(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e3be4-64f5-4a33-a957-44e1faed46e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader,labels = next(iter(train_loader))\n",
    "print(loader.shape)\n",
    "print(labels.view(8,8))\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(torchvision.utils.make_grid(loader,nrow=8).permute((1,2,0)))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c492d-20ae-4390-954b-0ebeeb085fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader,labels = next(iter(train_loader))\n",
    "print(loader.shape)\n",
    "print(labels.view(8,8))\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(torchvision.utils.make_grid(loader,nrow=8).permute((1,2,0)))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6882b6f-ae10-4aef-b8d4-54a258c0a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader,labels = next(iter(train_loader))\n",
    "print(loader.shape)\n",
    "print(labels.view(8,8))\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(torchvision.utils.make_grid(loader,nrow=8).permute((1,2,0)))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8b152-313f-4287-b13a-f267b55d72c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, n_epochs = 5):\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    test_accuracies = []\n",
    "    # set the model to train mode initially\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        since = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        for data in train_loader:\n",
    "\n",
    "            # get the inputs and assign them to cuda\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # calculate the loss/acc later\n",
    "            running_loss += loss.item()\n",
    "            running_correct += (labels==predicted).sum().item()\n",
    "\n",
    "        epoch_duration = time.time()-since\n",
    "        epoch_loss = running_loss/len(train_loader)\n",
    "        epoch_acc = 100/32*running_correct/len(train_loader)\n",
    "\n",
    "        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n",
    "        \n",
    "        losses.append(epoch_loss)\n",
    "        accuracies.append(epoch_acc)\n",
    "        \n",
    "        # switch the model to eval mode to evaluate on test data\n",
    "        model.eval()\n",
    "        test_acc = eval_model(model)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        # re-set the model to train mode after validating\n",
    "        model.train()\n",
    "        scheduler.step(test_acc)\n",
    "        since = time.time()\n",
    "    print('Finished Training')\n",
    "    return model, losses, accuracies, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c76bed-cb14-4fe6-b08a-6fb664b4f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            images, labels = data\n",
    "            # print(images)\n",
    "            print(labels)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_ft(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            print(predicted)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = 100.0 * correct / total\n",
    "    print('Accuracy of the network on the test images: %d %%' % (\n",
    "        test_acc))\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4cba7b-b26b-49d5-8bf0-432b838e485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft = models.resnet50(pretrained=True)\n",
    "# num_ftrs = model_ft.fc.in_features\n",
    "# \n",
    "# model_ft.fc = nn.Linear(num_ftrs, 8) #No. of classes = 10\n",
    "# model_ft = model_ft.to(device)\n",
    "model_ft = models.alexnet(pretrained=False)\n",
    "num_ftrs = model_ft.classifier[-1].in_features\n",
    "model_ft.classifier[-1] = nn.Linear(num_ftrs, 8)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "lrscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=20, threshold = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6953f9-7551-4259-a373-59be9ec31945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes around 5-6 minutes per epoch with GPU\n",
    "model_ft, training_losses, training_accs, test_accs = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc7e28-eea1-41a2-b7a3-f4dd18238ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Training losses')\n",
    "plt.plot(training_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81039f64-eeea-4304-bce6-2ea1af1ea10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Training Accuracy')\n",
    "plt.plot(training_accs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404937dd-291b-4131-ab01-c30d38903000",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Test Accuracy')\n",
    "plt.plot(test_accs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6bc9d3-8f45-4c1f-bf70-1fdad288fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), \"./alexnet_save_88/model-driver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a3a937-9c36-4c3e-bb86-380a38796aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet()\n",
    "num_ftrs = model_ft.classifier[-1].in_features\n",
    "model.classifier[-1] = nn.Linear(num_ftrs, 8)\n",
    "\n",
    "# model = models.resnet50()\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, 8)\n",
    "model.load_state_dict(torch.load(\"./alexnet_save_88/model-driver\"))\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b42b3ea-e328-4ff1-8e08-0a8852dd402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = \"/data/rkj/Rkj_code/project1/data_part_3\"\n",
    "list_img_test = [img for img in os.listdir(path_test) if not img.startswith(\".\")]\n",
    "list_img_test.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabbbdb3-baac-4e16-bf48-26b51778a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = random.choice(list_img_test)\n",
    "im_path = os.path.join(path_test,file)\n",
    "print(im_path)\n",
    "display(Image(filename=im_path))\n",
    "with PIL.Image.open(im_path) as im:\n",
    "    im = transform(im)\n",
    "    im = im.unsqueeze(0)\n",
    "    output = model(im.cuda())\n",
    "    print(output)\n",
    "    proba = nn.Softmax(dim=1)(output)\n",
    "    # proba = torch.argmax(output,dim=1)\n",
    "    proba = [round(float(elem),4) for elem in proba[0]]\n",
    "    print(proba)\n",
    "    print(\"Predicted class:\",class_dict[proba.index(max(proba))])\n",
    "    print(\"Confidence:\",max(proba))\n",
    "    proba2 = proba.copy()\n",
    "    proba2[proba2.index(max(proba2))] = 0.\n",
    "    print(\"2nd answer:\",class_dict[proba2.index(max(proba2))])\n",
    "    print(\"Confidence:\",max(proba2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0179fc5-1256-4e8a-a366-81751d201320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_pred(test_data,model):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    n = len(test_data)\n",
    "    sum = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in tqdm(test_data):\n",
    "            x = x.to(device)\n",
    "            pred = torch.argmax(model(x),dim=1)\n",
    "            print(y)\n",
    "            print(pred)\n",
    "            y_true.extend(list(np.array(y)))\n",
    "            y_pred.extend(list(np.array(pred.cpu())))\n",
    "    return y_true,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c946b-b1df-431a-bac1-1aeaf4060a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = confusion_matrix(y_true, y_pred)\n",
    "# m  = m.astype('float') / m.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a16d84-a742-408d-9bdb-cc3afa6e1719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建绘图\n",
    "plt.figure(figsize=(10, 8))  # 可以调整大小以适应你的数据规模\n",
    "\n",
    "# 绘制热力图并在每个方块中显示整数\n",
    "sns.heatmap(m, annot=True, fmt=\"d\", cmap='viridis', cbar=True)\n",
    "\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f829d77-bbb5-48c7-b5d2-611885853e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
